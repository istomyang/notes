# 微服务

## 服务发布、引用和掉用

服务描述：用什么方式对外描述服务，服务名称、提供的函数等，常见 Restful API 和 IDL（gRPC）。

注册中心：服务能注册、注销，消费者能获得列表、监听服务变化。

掉用的时候要注意超时和次数。

如果拉取服务列表，由于某个网络故障，突然网络压力很大，怎么办？这个时候可以考虑客户端缓存，向注册中心定期更新。

服务框架：服务通信采用什么协议？TCP 还是 UDP，HTTP 还是 其他协议？数据传输用什么方法？同步还是异步，是在单连接上传输，还是多路复用。数据压缩用什么格式？JSON 序列化 还是 Protobuf 序列化。

> 16-从0开始学微服务 03/04/11


## 服务监控

对于一个微服务来说，你必须明确要监控哪些对象、哪些指标，并且还要从不同的维度进行监控，才能掌握微服务的调用情况。

---

监控对象：

- 用户端监控：业务直接对用户提供的功能的监控，比如 用户如何使用功能的。

- 接口监控：业务提供的功能所依赖的具体 RPC 接口的监控。

- 资源监控：。

- 基础监控：服务器本身的健康状况的监控。主要包括 CPU 利用率、内存使用量、I/O 读写量、网卡带宽等。

---

监控哪些指标：

- 请求量：QPS，PV（Page View，用户访问量）。

- 响应时间：P99、P999 响应时间，服务质量（SLA）

- 错误率：接口调用失败占比。

--- 

监控哪些维度：

- 全局：目的是对监控对象有整体的了解，比如 请求量、平均耗时、错误率。

- 分机房：不同机房的全局情况。

- 单机：新采购的机器 和 以前的机器。

- 时间：一天时间内指标的变化，一段时间内变化。

- 核心：对核心业务更多的监控和预警，最好是分开监控，重点监控。

---

监控原理：监控系统流程，先 **数据采集**，然后数据传输到处理中心（**数据传输**），进行数据聚合分析，比如计算出各个指标然后存储起来（**数据处理**），最后通过接口或者Dashboard展示出来，这叫 **数据展示**。

- 数据采集：两种方式，1、服务主动上报，通过HTTP接口上传；2、代理收集，写到本地，然后用 ELK 去收集上报。需要考虑 采集频率，采样率，考虑磁盘I/O压力，CPU内存问题，不能影响主服务，最好是动态的，繁忙的时候降低收集占用。

- 数据传输：要么 UDP/TCP 这种传输，要么 Kafka 这种消息队列。主要考虑序列化的问题，网络压力问题。可以选择文本比如 JSON，也可以二进制比如 PB。

- 数据处理：一个是接口维度聚合，比如一个接口的请求量、平均耗时，还有一个就是机器维度，从单节点去看接口的请求量、平均耗时。最后存储，用索引数据库ES 或者 时序数据库 OpenTSDB。

- 数据展示：曲线图、饼状图、格子图（很多指标）。

---

落地

目前有两种方案：以 ELK 为代表的集中式日志解决方案，和 以 Graphite、TICK和Prometheus 为代表的时序数据库解决方案。

ELK（Elasticsearch、Logstash、Kibana）：

- Elasticsearch：负责数据处理，存储。

- Logstash：数据收集和传输，支持动态地从各种数据源收集数据，并对数据进行过滤、分析、格式化等，然后存储到指定的位置。

- Kibana：负责数据展示。

- Beats：代替 Logstash 数据收集的功能，性能比 Logstash 更好，可以收集 网络流量数据、系统进程和CPU内存使用情况数据、文件数据 和 Windows 事件日志收据。Beats 将收集到的数据发送到 Logstash，经过 Logstash 解析、过滤后，再将数据发送到 Elasticsearch，最后由 Kibana 展示，架构就变成下面这张图里描述的了。


Prometheus：

- Prometheus Server：用于拉取 metrics 信息并将数据存储在时间序列数据库。

- Jobs/exporters：用于暴露已有的第三方服务的 metrics 给 Prometheus Server，比如 StatsD、Graphite 等，负责数据收集。

- Pushgateway：主要用于短期 jobs，由于这类 jobs 存在时间短，可能在 Prometheus Server 来拉取 metrics 信息之前就消失了，所以这类的 jobs 可以直接向 Prometheus Server 推送它们的 metrics 信息。

- Alertmanager：用于数据报警。

- Prometheus web UI：负责数据展示。

流程：Prometheus Server 定期从配置好的 jobs 或者 exporters 中拉取 metrics 信息，或者接收来自 Pushgateway 发过来的 metrics 信息。然后 把收集到的 metrics 信息存储到时间序列数据库中，并运行已经定义好的 alert.rules，向 Alertmanager 推送警报。Alertmanager 根据配置文件，对接收的警报进行处理，发出告警。最后 通过 Prometheus web UI 进行可视化展示。


Graphite：组成主要包括三部分：Carbon、Whisper、Graphite-Web

TICK： 是 Telegraf、InfluxDB、Chronograf、Kapacitor 四个软件首字母的缩写。


选型：

- ELK 的技术栈比较成熟，应用范围也比较广，除了可用作监控系统外，还可以用作日志查询和分析。

- Graphite 是基于时间序列数据库存储的监控系统，并且提供了功能强大的各种聚合函数比如 sum、average、top5 等可用于监控分析，而且对外提供了 API 也可以接入其他图形化监控系统如 Grafana。

- TICK 的核心在于其时间序列数据库 InfluxDB 的存储功能强大，且支持类似 SQL 语言的复杂数据处理操作。

- Prometheus 的独特之处在于它采用了拉数据的方式，对业务影响较小，同时也采用了时间序列数据库存储，而且支持独有的 PromQL 查询语言，功能强大而且简洁。


> 16-从0开始学微服务 03/07/15


## 服务追踪

作用：

- 优化系统瓶颈：拿到每个服务的耗时，针对性优化。

- 优化链路调用：拿到掉用链路，对深度进行优化。

- 生成网络拓扑：拿到整体掉用结构图，进行分析优化。

- 透明传输数据：比如 A/B测试，某个请求带有一些信息，每个服务针对这个信息做一些调整。


原理：

论文：Dapper, a Large-Scale Distributed Systems Tracing Infrastructure，核心理念就是 调用链：通过一个全局唯一的 ID 将分布在各个服务节点上的同一次请求串联起来，从而还原原有的调用关系，可以追踪系统问题、分析调用数据并统计各种系统指标。

traceId：标识某一次具体的请求 ID，用来串联某一次请求所有路径。

spanId：标识一次 RPC 调用在分布式请求中的位置，比如 123,345,12,545 就能拿到分别掉用了哪个服务。

annonation：用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户 UID。

【 如果拿到耗时数据，是不是可以根据调用链画火焰图？ 】

实现：

分三层：1、数据采集层，负责数据埋点并上报。2、数据处理层，负责数据的存储与计算。3、数据展示层，负责数据的图形化展示。

- 数据采集层：在系统的各个不同模块中进行埋点，采集数据并上报给数据处理层进行处理。

- 数据处理层：把数据采集层上报的数据按需计算，然后落地存储供查询使用。分为 实时计算 和 离线计算，实时计算，一般用 Storm 和 Spark Streaming，使用 OLTP 数据仓库，比如 HBase。离线计算用 MapReduce 或 Spark，存储用 Hive。

- 数据展示层：将处理后的链路信息以图形化的方式展示给用户，比如 调用链图。


--- 

实施：业界比较有名的服务追踪系统实现有阿里的鹰眼、Twitter 开源的 OpenZipkin，还有 Naver 开源的 Pinpoint，它们都是受 Google 发布的 Dapper 论文启发而实现的。其中阿里的鹰眼解决方案没有开源，而且由于阿里需要处理数据量比较大，所以鹰眼的定位相对定制化，不一定适合中小规模的业务团队。

还有 Jaeger。

选型考量：

1. 埋点探针支持平台的广泛性，不能某些语言不支持。

2. 系统集成难易程度。

3. 调用链路数据的精确度。


> 16-从0开始学微服务 03/08/16


## 服务治理

改成微服务后需要面对的问题：

1. 注册中心宕机；

2. 服务提供者 B 有节点宕机；

3. 服务消费者 A 和注册中心之间的网络不通；

4. 服务提供者 B 和注册中心之间的网络不通；

5. 服务消费者 A 和服务提供者 B 之间的网络不通；

6. 服务提供者 B 有些节点性能变慢；

7. 服务提供者 B 短时间内出现问题。


常用的服务治理手段：

- 注册中心主动摘除机制：节点需要定时向注册中心汇报健康，超时就会被摘除，告警。

- 服务消费者摘除机制：一般为了减轻注册中心的压力（定期）会缓存服务列表，有些时候，因为网络问题，注册中心会摘除健康的节点，这个时候需要客户端去操作。

- 负载均衡：随机算法、轮训算法（按照固定顺序）、最少活跃、一致性Hash。

- 服务路由：灰度发布需求、多机房时就近访问，路由可以静态配置，也可以动态配置，各有利弊。

- 服务容错：FailOver（失败自动切换节点）、FailBack（根据失败信息决定后续策略）、FailCache（隔一段时间重试）、FailFast（快速失败返回）。

---

识别节点是否存活：

- 心跳开关保护机制：如果网络抖动，注册中心会频繁更新可用节点，这个时候通知消费者，整个网络很有压力。方法：先通知一部分，或者 延迟通知。

- 服务节点摘除保护机制：网络抖动的时候，注册中心下架了大量节点，这个时候需要阈值来保护最低可用节点。因为正常情况下不会这样，所以往往是注册中心与服务提供者之间网络挂了。

- 静态注册中心：让消费端来探测服务是否存活。

【 要提供一个消费端报告的接口，让消费端判断服务节点是否健康，但是也要考虑多个消费节点报告失败才认定注册中心节点不可用。 】

---

负载均衡算法的使用场景：

- 随机算法：通过概率达到 均衡。

- 轮询算法：通过 固定顺序 达到 均衡。

- 加权轮询算法：机器性能差异比较大。

- 最少活跃连接算法：性能均衡。

- 一致性 hash 算法：某些请求依赖节点的状态。

- 自适应最优选择算法：自己开发，开发一个服务，根据自己的需要切换策略。

---

服务路由 就是服务消费者在发起服务调用时，必须根据特定的规则来选择服务节点，从而满足某些特定的需求。

应用：

- 分组调用：服务节点也会按照不同的数据中心分成不同的分组，这时对于服务消费者来说，选择哪一个分组调用，就必须有相应的路由规则。

- 灰度发布：也叫 金丝雀部署。

- 流量切换：把原来调用这个机房服务的流量切换到其他正常的机房。

- 读写分离：读多写少场景。

路由获取方式：

- 本地配置，静态的路由。

- 配置中心，统一的获取。

- 动态下发，动态的修改。

如果三个一起用，可以使用它的长处。

--- 

服务端故障处理方法

- 集群故障：限流和降级。
	限流就是限制流量，剩下的返回错误。
	降级就是关闭非核心功能。降级的话，最好规定好降级的等级，然后各服务归属，这样能快速降级。

- 单 IDC 故障：一种是基于 DNS 解析的流量切换，一种是基于 RPC 分组的流量切换。
	
- 单机故障：先找出什么问题再说。

---

掉用失败处理方法

- 超时。给每个调用一个超时时间，所以这个时候 P999 和 P9999 指标很重要。

- 重试。从概念角度，10%失败 乘以 10%失败 概率更小。

- 双发。通过两条路就获取信息，出问题可以，但正常会造成浪费，这个时候可以这样：对某个请求使用一个相对乐观的超时时间，一般 P999 和 P9999 的 20% 或者平均值，一旦超过这个值，就去双发。

- 熔断。如果某一段时间内，服务调用失败的次数达到一定阈值，那么断路器就会被触发，后续的服务调用就直接返回，也就不会再向服务提供者发起请求了。半打开状态：每隔一段时间，去探测看看是否恢复正常。

---

微服务治理平台：与服务打交道的统一入口，类似于 网页版的 Kubectl。


> 16-从0开始学微服务 03/09/17/18/19/20/21/22/23