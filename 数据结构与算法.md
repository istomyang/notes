# 数据结构与算法


## 数组

数组特性：线性表、连续的内存空间和相同的类型。

数组有个杀手锏：随机访问。根据下标随机访问的时间复杂度为 O(1)。

数组插入需要挪移，最差情况On，有一思想，如何对数组有序没有要求，可以把插入位置元素挪到最后，然后插入进去，这个操作是 O(1)。

数组删除需要挪移，情况同插入，这个时候可以先标记被删除的数据，然后按批次删除，这个思想也是JVM的标记清除垃圾回收算法。

数组从0开始，一个是这个0不是位置是偏移，另一个我认为是方便取模。

> 01-数据结构与算法之美-05


## 链表

单链表：

循环链表：单链表的尾结点指针指向空地址，表示这就是最后的结点了，而循环链表的尾结点指针是指向链表的头结点。

双向链表：进一步提高链表节点的查找能力。

双向循环链表：

数组 VS 链表：复杂度、数组可以借助CPU缓存机制而链表不行、数组1.5倍扩容有时候是浪费我认为可以分片。

链表实现 LRU：从头开始遍历，如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。如果此数据没有在缓存链表中，又可以分为两种情况：如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。我们可以 **引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。**

> 01-数据结构与算法之美-06

哨兵 Sentinel：用来解决边界条件问题，比如判断头尾为NULL，所以用了哨兵之后，可以按照正常的节点处理。


> 链表写技巧看 01-数据结构与算法之美-07


## 栈

后进者先出，先进者后出，这就是典型的“栈”结构。

可以屏蔽数组或链表的功能来实现栈，前者叫 顺序栈，后者叫 链式栈。

栈用来表达式求值，看图 01-数据结构与算法之美-08。

栈用来匹配括号。

> 01-数据结构与算法之美-08


## 队列

先进者先出，这就是典型的“队列”，也是对数组/链表功能进行屏蔽。

顺序队列：用数组实现的。

链式队列：用链表实现的。

循环队列：用来解决顺序队列中数据挪移的问题，当队列满时，放到开头，然后等指针到末尾时再一到开始继续遍历。

阻塞队列：队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。—— 生产者 - 消费者模型

并发队列：解决 阻塞队列 线程安全问题，加锁，或者 CAS。

> 01-数据结构与算法之美-09


## 跳表

跳表 是对 链表 进行改造以满足二分查找的需求，甚至可以替代红黑树（Red-black tree）。

跳表的空间复杂度：O(n)，但是有操作空间，我认为，跳表最大的优势是 动态加密：如果是热点数据，加密上一层节点，如果冷数据，就可以减少上层节点，这层通过遍历链表来实现查找。

跳表通过随机函数来平衡索引节点的位置，而红黑树通过左右旋来保持平衡。

跳表 VS 红黑树：跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好写多了，而简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

> 01-数据结构与算法之美-17


## 散列表

散列表刚开始就是利用数组随机访问的特性，通过Key计算位置实现快速定位。

散列函数：MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等，最好保证均匀。

散列冲突：数组的存储空间有限，会加大散列冲突的概率。解决方法：开放寻址法（open addressing）和链表法（chaining）。

开放寻址法：如果Hash后发现位子有，那在后面找一个空填入。本质上 用时间换空间，下次查找的时候，搜索范围就是，Hash作为起始位置，终点代表NULL，所以删除的时候，只能标记不能直接删除，因为终点是NULL。

📝 开放寻址法的好处就是，因为存储在数组里，可以利用 CPU 缓存加快查询速度，而且这种方法 散列函数 相对简单。适用场景：当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。

二次探测（Quadratic probing）：在 开放寻址法 基础上，从线性变成二次方。因为 开放寻址法 最坏的情况是 On，用二次一定来说避免。

双重散列（Double hashing）：如果冲突，再Hash一遍，本质上 时间换空间，然后查找的时候，也要多次Hash进行比较。

装载因子（load factor）：装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

链表法：使用链表存储相同Hash的元素，我认为，这个方法好处就是，不会增大系统总混乱程度。之前的方法，都是通过占满空闲的位子，意味着随着时间推移，越来越容易冲突。

📝 链表法 比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用 红黑树、跳表 代替链表。

动态扩缩容：需要重新申请内存空间，然后重新计算Hash位置，这个行为可以平摊，最后 O1 的复杂度，方法就是，每次查询的时候，先确定在旧表还是新表，如果是旧表，从旧表里取返回，然后重新计算Hash放到新表里，然后修改路有记录，有的时候可以顺带邻居一起搬走。

散列表 和 链表 经常一起用是一个利器，散列表可以解决链表 On 的问题。

> 01-数据结构与算法之美-18
> 01-数据结构与算法之美-19
> 01-数据结构与算法之美-20


## 二叉树

先去 01-数据结构与算法之美-23 了解清楚：父节点、兄弟节点、子节点、根节点、叶子节点、非叶子节点、高度、深度、层。

二叉树：每个节点最多有两个“叉”。

满二叉树：叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点。

完全二叉树：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大。

为什么存在 “完全二叉树”，而且必须往左靠，是因为存储，用数组存储最节省内存。

---

存储方法：

链式存储法：用节点存储，用指针连接。

顺序存储法：用数组来存储，完全二叉树 的由来。

---

二叉树的遍历：前序遍历、中序遍历和后序遍历。

前序遍历：对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。

中序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。

后序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。

【 前中后，对应到中间节点，然后顺序都是左到右。 】

二叉树遍历的时间复杂度是 O(n)。

---

二叉查找树（Binary Search Tree）

二叉查找树特性：在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

排序：中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)，非常高效，所以 二叉查找树 也叫 二叉排序树。

支持重复数据：1、节点使用链表。2、按大于处理。

时间复杂度其实都跟树的高度成正比，也就是 O(height)。

平衡二叉查找树的高度接近 logn，所以插入、删除、查找操作的时间复杂度也比较稳定，是 O(logn)。

散列表 VS 二叉查找树：
1. 散列表中的数据是无序存储的，二叉查找树中序遍历即可。
2. 散列表扩容耗时很多，性能不稳定，平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
3. 尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。
4. 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。
5. 为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。


> 01-数据结构与算法之美-23
> 01-数据结构与算法之美-24


## 红黑树

红黑树（Red-Black Tree，R-B Tree） 属于 平衡二叉树 的一种，其他还有 Splay Tree（伸展树）、Treap（树堆）、AVL 树 等。

平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。

红黑树是“近似平衡”的。“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化的太严重。

红黑树的平衡要固定算法，根据什么样的节点排布，做出调整。只要保证4个规则就行。

红黑树之所以有颜色区分，有节点必须是黑色的NULL节点这些规定，就是为了固定调整算法用的，这样所有的情况都可以用固定流程去做。


> 01-数据结构与算法之美-25
> 01-数据结构与算法之美-26


## 递归树

递归树 可以来分析递归算法的时间复杂度。

> 01-数据结构与算法之美-27


## 堆

堆和堆排序

堆：完全二叉树 并且 每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

大顶堆 和 小顶堆

因为 完全二叉树 ，堆可以用 数组 实现。

堆顶删除的时候，右下角节点放入删除的位置，重新排列。

> 01-数据结构与算法之美-28

---

堆的应用1：优先级队列

用堆来实现 优先级队列 是最直接、最高效的。

实现：往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

优先级队列，它的应用场景非常多：赫夫曼编码、图的最短路径、最小生成树算法等。

优先级队列应用1：合并有序小文件。比如 100个文件，文件100MB，思路就是，先文件内排序，然后100个文件各取一个数比较大小，加入堆上，然后删除。


优先级队列应用2：高性能定时器。就不需要每1秒都要扫描一遍列表。

---

堆的应用2：利用堆求 Top K

---

堆的应用3：利用堆求中位数

可以动态的计算中位数，因为中位数的位置是确定的，数字是流动的。

快速求接口的 99% 响应时间 也是用的堆。

---

> 01-数据结构与算法之美-29


## 图

图的算法有很多：图的搜索、最短路径、最小生成树、二分图等。

---

概念

顶点（vertex）：图中的元素。

边（edge）：图中的一个顶点可以与任意其他顶点建立连接关系。

度（degree）：跟顶点相连接的边的条数。

有向图：边有方向。

入度（In-degree）：有多少条边指向这个顶点。

出度（Out-degree）：有多少条边是以这个顶点为起点指向其他顶点。

带权图（weighted graph）：每条边都有一个权重（weight）。

---

存储方法：

邻接矩阵（Adjacency Matrix）：如果是 稀疏图（Sparse Matrix），顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。优点：1、存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。2、方便计算，很多图的运算转换成矩阵之间的运算。

邻接表（Adjacency List）：

我们可以将邻接表中的链表改成平衡二叉查找树。实际开发中，我们可以选择用红黑树。这样，我们就可以更加快速地查找两个顶点之间是否存在边了。

这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。


> 01-数据结构与算法之美-30


## Trie树

Trie 树，也叫“字典树”。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。

Trie 树比较适合的是查找前缀匹配的字符串，不适合精确匹配查找。

Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。

在某些情况下，Trie 树不一定会节省存储空间。在重复的前缀并不多的情况下，Trie 树不但不能节省内存，还有可能会浪费更多的内存。

Trie 树的变体有很多，都可以在一定程度上解决内存消耗的问题。

缩点优化：就是对只有一个子节点的节点，而且此节点不是一个串的结束节点，可以将此节点与子节点合并。

> 01-数据结构与算法之美-35


## 布隆过滤器

原理：当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。

布隆过滤器的误判有一个特点，它只会对存在的情况有误判。如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判。

> 布隆过滤器 Wiki https://zh.wikipedia.org/zh-hans/布隆过滤器
> 01-数据结构与算法之美-45

## 并查集

并查集（Union & Find）主要处理不相交集（Disjoint Sets）的合并和查询问题。

Find：确定一个元素属于哪个子集，两个元素是否属于同一个子集。原理就是，通过不断递归找到节点的Root，然后判定两个 Root 是否相等。

Union：将两个子集合并成一个集合。原理就是递归找到 Root，然后让一个Root成为另一个Root的father。

应用场景：帮派识别，公司组织人员识别。

并查集优化1：小组织纳入到大组织里，降低深度（Rank），寻找更加高效。

并查集优化2：路径压缩，所有子节点指向唯一的Root。



> 70-算法面试通关40讲 52

==================================================================

## 递归

递归需要满足的三个条件：
1. 一个问题的解可以分解为几个子问题的解。
2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。
3. 存在递归终止条件。

编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。

写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。

【 先假设有3个，然后推广到n个。 】

递归代码要警惕堆栈溢出。

递归代码要警惕重复计算，可以用 HashMap 保存结果方便复用。

递归改递推：用栈来解决。

> 01-数据结构与算法之美-10


## 排序

要区分 最好情况、最坏情况、平均情况时间复杂。因为具体的使用场景限制。

要关注 时间复杂度的系数、常数 、低阶。因为规模往往相同，这个时候就看次要因素。

要关注 内存消耗，还有 原地排序（Sorted in place）。

要关注 算法稳定稳定性：不稳定排序可能会改变相同元素的相对位置。用处就是，有时候比较大小的同时，保证其他数据稳定的，比如时间戳。

有序度：就是这个数组多大程度是有序的，量化方法就是，数多少个对满足 a > b。

逆序度：满序度 - 有序度。

要关注 有序度，有的时候，有序度高在某些排序算法中效率就越高，比如插入排序。


- 冒泡排序（Bubble Sort）：重复遍历未排序，比较相邻元素大小，然后交换，就会把大的一步步往右边推，重复直到有序。平均时间On^2，最好就是有序On，最坏On^2，空间O1，稳定。

- 选择排序：重复遍历未排序，每次找到最小的放到前面，一直到有序。平均时间On^2，最好就是有序On^2，最坏On^2，空间O1，不稳定。

- 插入排序：打牌，遍历一遍，对每个元素放到有序合适的位置，一直到结尾。平均时间On^2，最好就是有序On，最坏On^2，空间O1，稳定。

- 希尔排序：插入排序的改进，思想就是插入排序对差不多有序的数据效率非常高，所以希尔排序就是把数据分成若干进行插入排序，等“基本有序”后，全体再进行插入排序，另外可以用并行算法。平均时间Onlogn，最好就是有序Onlog2n，最坏Onlog2n，空间O1，不稳定。

- 归并排序：分成N份数据，分别排序，通过 递归/递推 两两合并，怎么合并，用两个指针在两组数据上，比较大小，挑出小的，指针后移，直到有序。也可以总共16份，用16个指针，用堆排序找最小的，减少递归树高度。平均时间Onlogn，最好就是有序Onlogn，最坏Onlogn，空间On，稳定。

- 快速排序：找一个基准，遍历一遍，小的放前面，大的放后面，然后重复递归两段数据，就是牵涉到 分区partition 的操作。平均时间Onlogn，最好就是有序Onlog2n，最坏On^2，空间Ologn，不稳定。

- 堆排序：堆的特性，父节点总是大于/小于子节点，从底下往上遍历，如果不满足特性，就交换节点，一直到最上面，拿出来，继续重复剩下的。平均时间Onlogn，最好就是有序Onlogn，最坏Onlogn，空间O1，不稳定。

📝 堆排序问题：1、跳着访问数据，不利于CPU缓存。2、对于同样数据，堆排序交换次数多于快排。

> 堆排序细节：01-数据结构与算法之美-28

- 计数排序：前提必须是确定范围的整数，相当于分原子桶。平均时间On+k，最好就是有序On+k，最坏On+k，空间Ok，稳定。

- 桶排序：基于范围分片，尽可能利用内存空间，分布要均匀，最差情况就是一个桶占了大部分数据。桶排序也可以用到外部排序里。平均时间On+k，最好就是有序On^2，最坏On+k，空间On+k，稳定。

- 基数排序：整数排序，利用的是位数进行分桶。平均时间On*k，最好就是有序On*k，最坏On*k，空间On+k，稳定。

数据结构与算法之美 包含 十大算法（没有堆好像），有图片讲解，可以辅助理解。

> [十大经典排序算法](https://www.runoob.com/w3cnote/ten-sorting-algorithm.html )
> 01-数据结构与算法之美-11
> 01-数据结构与算法之美-12
> 01-数据结构与算法之美-13
> 01-数据结构与算法之美-14 排序优化


## 二分查找

二分查找的核心：每一次都把搜索范围减少一半。

二分查找局限：
1. 依赖的是顺序表结构，简单点说就是数组，链表不行。
2. 二分查找针对的是有序数据。
3. 数据量太小不适合二分查找。优势体现不出来。
4. 数据量太大也不适合二分查找。因为依赖数组，数组必须是连续的，内存分配有点困难。

二分查找变形问题：
1. 变体一：查找第一个值等于给定值的元素。
2. 变体二：查找最后一个值等于给定值的元素。
3. 变体三：查找第一个大于等于给定值的元素
4. 变体四：查找最后一个小于等于给定值的元素

这些问题本质上就是，在特殊化的操作步骤上，对范围的缩小进行特殊处理，包括往前去检查元素，往后去检查元素。

> 01-数据结构与算法之美-15
> 01-数据结构与算法之美-16


## 深度和广度优先搜索

广度优先搜索（Breadth-First-Search），我们平常都把简称为 BFS。直观地讲，它其实就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。

BFS 代码需要记录的东西：
1. visited 已经访问过的节点，用 Hash表，也可以标记法。
2. queue 已经访问过节点，但相连的节点没有访问。
3. prev 记录搜索路径，Hash表，Key是评估值，Value是路径，比如Key为最短路径长度。

BFS 时间复杂度：最坏情况下，终止顶点 t 离起始顶点 s 很远，需要遍历完整个图才能找到。这个时候，每个顶点都要进出一遍队列，每个边也都会被访问一次，所以，广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数。当然，对于一个连通图来说，也就是说一个图中的所有顶点都是连通的，E 肯定要大于等于 V-1，所以，广度优先搜索的时间复杂度也可以简写为 O(E)。

BFS空间复杂度：消耗主要在几个辅助变量 visited 数组、queue 队列、prev 数组上。这三个存储空间的大小都不会超过顶点的个数，所以空间复杂度是 O(V)。

---

深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。

DFS时间复杂度：每条边最多会被访问两次，一次是遍历，一次是回退。所以，图上的深度优先搜索算法的时间复杂度是 O(E)，E 表示边的个数。

DFS空间复杂度：主要是 visited、prev 数组和递归调用栈。visited、prev 数组的大小跟顶点的个数 V 成正比，递归调用栈的最大深度不会超过顶点的个数，所以总的空间复杂度就是 O(V)。


> 01-数据结构与算法之美-31


## 哈希算法

优秀哈希算法的要求：
1. 从哈希值不能反向推导出原始数据；
2. 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
3. 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
4. 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

应用：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

---

安全加密：

最常用于加密的哈希算法是MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和SHA（Secure Hash Algorithm，安全散列算法）。

还有很多其他加密算法，比如DES（Data Encryption Standard，数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。

冲突的原理：我认为是信息论，如果概述的信息量小于文本原本的信息量，必然是存在冲突。

冲突概率很小，而且现在密码学研究破解时间很长很长的加密算法。

所以使用的时候，权衡破解难度和计算时间。

对于字典攻击，可以引入 一个盐（salt），增加密码的复杂度。

--

唯一标识：

对资源进行标识，可以快速知道一个大资源是否存在，用MD5之类的。

---

数据校验：

下载文件数据校验，比如 BT协议。

---

散列函数：

散列函数对于散列算法冲突的要求要低很多。

散列函数对于散列算法计算得到的值，是否能反向解密并不关心。

散列函数中用到的散列算法，更加关注散列后的值是否能平均分布。

散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

---

负载均衡：

需求：同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

方法：对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 

---

数据分片：

问题：假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

方法：我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。

这也是 MapReduce 的基本设计思想：用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

问题：有 1 亿张图片，如何快速判断图片是否在图库中？

方法：对数据进行分片，然后采用多机处理。我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。

估算很重要：假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。

---

分布式存储：

问题：如果10台机子不够用了，扩容咋办？如果在线上缓存系统里，是不是容易雪崩？

方法：一致性哈希算法。使用一个环来划分区间，如果加入新的机器，就把这个小区域的数据迁移就可以了，Memcache 用的这个方法。


> 01-数据结构与算法之美-21
> 01-数据结构与算法之美-22


## 字符串匹配

主串：被查找的字符串文章。

模式串：查找的字符串。

### BF 算法

BF 算法中的 BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。

BF 算法的思想：我们在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。—— 通过移动模式串进行对比。

BF 算法的时间复杂度很高，是 O(n*m)，但在实际的开发中，它却是一个比较常用的字符串匹配算法。

实际的软件开发中，大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。

朴素字符串匹配算法思想简单，代码实现也非常简单。简单意味着不容易出错，如果有 bug 也容易暴露和修复。

在工程中，在满足性能要求的前提下，简单是首选。这也是我们常说的KISS（Keep it Simple and Stupid）设计原则。

> 01-数据结构与算法之美-32

### RK 算法

RK 算法的全称叫 Rabin-Karp 算法，由它的两位发明者 Rabin 和 Karp 的名字来命名的。

RK 算法思想：在BF的基础上，对所有子串求Hash，然后比对就可以了。

Hash的设计比较重要，字符串匹配有个特性，前后两个子串，去头增尾，中间大部分内容是不变的，那就可以简化Hash的计算，并且允许一部分冲突（退化到BF算法）。

如果字符在a-z，可以用26进制设计Hash算法。

Hash设计的好：比较的时间复杂度是 O(1)，时间复杂度是 O(n)。


> 01-数据结构与算法之美-32


### BM 算法

BM（Boyer-Moore）算法 有实验统计，它的性能是著名的KMP 算法的 3 到 4 倍。

BM 算法思想：当遇到不匹配的时候，有什么办法多往后挪几个？

---

坏字符规则（bad character rule）

BM对比是倒着的，先比较最后面的，如果最后面的不匹配，检查匹配串前面的字符是否匹配，如果都不匹配，直接向前移动 匹配串长度，否则，把相同的字符对齐。

坏子串的问题：aaaaaaaaaaaaaa 找 baaaa 这种情况，最差情况。

---

好后缀规则（good suffix shift）

好后缀规则实际上跟坏字符规则的思路很类似。

在模式串找到一个根主串相同的部分，然后对齐到主串相应位置。

---

分别计算好后缀和坏字符往后滑动的位数，然后取两个数中最大的，作为模式串往后滑动的位数。

TODO：01-数据结构与算法之美-33


> 01-数据结构与算法之美-33


### KMP 算法

KMP 算法是根据三位作者（D.E.Knuth，J.H.Morris 和 V.R.Pratt）的名字来命名的，算法的全称是 Knuth Morris Pratt 算法，简称为 KMP 算法。

KMP 算法的核心思想：在模式串与主串匹配的过程中，当遇到不可匹配的字符的时候，我们希望找到一些规律，可以将模式串往后多滑动几位，跳过那些肯定不会匹配的情况。

TODO：01-数据结构与算法之美-34

> 01-数据结构与算法之美-34


### Trie 树

> 01-数据结构与算法之美-35

### AC 自动机

AC 自动机算法，全称是 Aho-Corasick 算法，

> 01-数据结构与算法之美-36


## 贪心算法

贪心算法（greedy algorithm）就是每一个步骤都是最优解。

适用场景：1、问题都被分成子问题来解决。2、子问题的最优解能递推到问题的最优解。

因为现实生活中很多场景并不是这样，所以 动态规划 就出来了，贪心是每一步最优，动态规划是综合考虑所有情况。

贪心算法 有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。最小生成树算法和最短路径算法。

霍夫曼编码，去看看哈夫曼树。

> 01-数据结构与算法之美-37


## 分治算法

分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。

MapRedue 的本质就是分治算法。

> 01-数据结构与算法之美-38

## 回溯算法

深度优先搜索算法利用的是回溯算法思想，还有 正则表达式匹配、编译原理中的语法分析。

回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。

> 01-数据结构与算法之美-39


## 动态规划

动态规划（Dynamic Programming）就是把问题拆解为子问题，然后保存所有可能的结果，每一步都保存一个当前步最优的解，一直到最后一步，f[m][n] = 最优。

> 01-数据结构与算法之美-40
> 01-数据结构与算法之美-41
> 01-数据结构与算法之美-42


## 索引

实际上，常用来构建索引的数据结构，就是我们之前讲过的几种支持动态数据集合的数据结构。比如，散列表、红黑树、跳表、B+ 树。除此之外，位图、布隆过滤器可以作为辅助索引，有序数组可以用来对静态数据构建索引。

散列表增删改查操作的性能非常好，时间复杂度是 O(1)。一些键值数据库，比如 Redis、Memcache，就是使用散列表来构建索引的。这类索引，一般都构建在内存中。

红黑树作为一种常用的平衡二叉查找树，数据插入、删除、查找的时间复杂度是 O(logn)，也非常适合用来构建内存索引。Ext 文件系统中，对磁盘块的索引，用的就是红黑树。

B+ 树比起红黑树来说，更加适合构建存储在磁盘中的索引。B+ 树是一个多叉树，所以，对相同个数的数据构建索引，B+ 树的高度要低于红黑树。当借助索引查询数据的时候，读取 B+ 树索引，需要的磁盘 IO 次数非常更少。所以，大部分关系型数据库的索引，比如 MySQL、Oracle，都是用 B+ 树来实现的。

跳表也支持快速添加、删除、查找数据。而且，我们通过灵活调整索引结点个数和数据个数之间的比例，可以很好地平衡索引对内存的消耗及其查询效率。Redis 中的有序集合，就是用跳表来构建的。

布隆过滤器有一定的判错率。但是，我们可以规避它的短处，发挥它的长处。尽管对于判定存在的数据，有可能并不存在，但是对于判定不存在的数据，那肯定就不存在。

有序数组也可以被作为索引。如果数据是静态的，也就是不会有插入、删除、更新操作，那我们可以把数据的关键词（查询用的）抽取出来，组织成有序数组，然后利用二分查找算法来快速查找数据。

> 01-数据结构与算法之美-50


## 并行算法

并行排序

- 对归并排序并行化处理。划分16个数据块，并行排序，然后合并数据块。

- 对快速排序并行化处理。扫描一遍，划分16个区间，让数据在对应到区间里，然后并行排序。

思想就是对数据进行分片，如果数据大小是 1TB，就需要外排序，这个时候思考一下。

---

并行查找

用 散列表 构建查找结构，遇到源源不断的数据，可能还需要扩容，会浪费很多空间，这个时候可以把大 散列表 切割成 几十份，这样就避免了大容量扩容，而且可以并行读。

多个散列表可以降低并发的锁竞争。

---

并行字符串匹配

把字符串拆开几十份，分别开线程去查，注意 子字符串 首位需要有一定的重合，这样不至于因为截断找不到。

---

并行搜索

广度优先搜索的并发方法：用两个队列，队列A 并行处理当前层，然后把扩展的节点加入到 队列B，等 队列A 处理完清空，交换 A 和 B，同样的逻辑处理 队列B。 


> 01-数据结构与算法之美-51


## 拓扑排序

拓扑排序有两种实现方法，都不难理解。它们分别是Kahn 算法和DFS 深度优先搜索算法。

> 01-数据结构与算法之美-43


## 朴素贝叶斯算法

> 01-数据结构与算法之美-46








