# Golang

## 并发编程

并发编程练成了两种境界：

1. 对既有的并发原语进行组合，比如 信号量 + WaitGroup = 有限并发。

2. 无中生有，创造新的并发原语，比如如果标准库没有信号量，自己可以创造出来。

> 08-Go并发编程实战课 开篇词

### Mutex

临界区：只能由一个线程持有，其他线程会返回失败或者等待。

可以使用 Go race detector 来检测代码运行时的不安全访问，这个工具的原理是在代码中插入指令检测逻辑，缺点就是必须实际运行才能检测出，所以如果有依赖日期的代码，可能就检测不出来。

> 08-Go并发编程实战课 01

CAS（compare-and-swap，或者 compare-and-set）是原子操作，CAS 指令将给定的值和一个内存地址中的值进行比较，如果它们是同一个值，就使用新值替换内存地址中的值。

**Mutex 不会检查线程的ID，意思是线程也可以释放锁，所以 “谁申请，谁释放” 原则。**

Go Mutex发展阶段：

1. 初版：使用两个字段，一个是标识锁状态，一个是等待者队列的信号量。缺点：一些线程正好处于CPU分片，这个时候直接交给它，就不需要刷新缓存，切换上下文。

2. 给新人机会：相比于1版，如果锁已经释放，新的线程就会获得，不需要到后面排队。

3. 多给些机会：相比于2版，如果锁未释放，新的线程通过自旋（Spin，循环尝试）来获得锁，因为临界区代码很快，就不需要让新线程进入休眠然后再唤醒，浪费CPU时间。缺点：一些老的线程可能一直得不到锁。

4. 解决饥饿：相比于3版，设定一个1毫秒阈值，如果超过这个时间，就停下重点解决老线程的问题。

> 08-Go并发编程实战课 02

易错场景：

- Lock/Unlock 不是成对出现。我认为，少用 defer，因为最大化减少临界区代码，让语句赶紧结束。

- Copy 已使用的 Mutex。因为 Mutex 是有状态的。

- 重入。因为不检测线程ID，这里可以创造一个可重入锁，有两种方式，通过运行时拿到 goroutine id 和 使用 Token 来标识 goroutine。

- 死锁。我认为避免死锁，有两个方法，第一个是减少临界区代码，快速释放锁，第二个是，所有线程遵循同样对资源的访问顺序。

可以通过一些工具去检测到，比如 go-deadlock、go-tools。

如果异常，可以 Go pprof 工具分析，它提供了一个 block profiler 监控阻塞的 goroutine。

> 08-Go并发编程实战课 03

锁是性能下降的“罪魁祸首”之一，所以，有效地降低锁的竞争，就能够很好地提高性能。因此，监控关键互斥锁上等待的 goroutine 的数量，是我们分析锁竞争的激烈程度的一个重要指标。

扩展：

- 实现 TryLock。

- 获取等待者数量。

- 线程安全的队列。

> 08-Go并发编程实战课 04


### RWMutex

Go 标准库中的 RWMutex 是基于 Mutex 实现的。

readers-writers 问题一般有三类，基于对读和写操作的优先级，读写锁的设计和实现也分成三类：

1. Read-preferring：所有读释放锁之后，写才能获取锁，容易导致写饥饿。

2. Write-preferring：一旦写锁等待，写锁等待前面的读锁，后面的读锁等待写锁，容易导致读饥饿。

3. 不指定优先级：不再区分读写，大家都是同一个优先级，解决了饥饿的问题。

Go 标准库中的 RWMutex 设计是 Write-preferring 方案。一个正在阻塞的 Lock 调用会排除新的 reader 请求到锁。

问题：

1. 不可复制。

2. 重入导致死锁。比如 递归 调用，所以 递推 的重要性。

3. 释放未加锁的 RWMutex。

> 08-Go并发编程实战课 05


### WaitGroup

原理：在调度的时候，加1，然后线程完成的时候，减1，然后 Wait 方法就是时刻监视 值是否等于0，等于就直接返回，不等于就阻塞自己。

注意：

1. 不用多调用 Add 也不要少调用 Done。

2. 调用 Add 应该在启动异步之前，Done应该在异步里面调用。

3. WaitGroup 是可以重复使用的，但必须等前面的 Wait 结束。

如果你想要自己定义的数据结构不被复制使用，或者说，不能通过 vet 工具检查出复制使用的报警，就可以通过嵌入 noCopy 这个数据类型来实现。

> 08-Go并发编程实战课 06


### Cond

Cond 条件变量：为等待 / 通知场景下的并发问题提供支持。

在实践中，处理等待 / 通知的场景时，我们常常会使用 Channel 替换 Cond，因为 Channel 类型使用起来更简洁，而且不容易出错。

调用 cond.Wait 方法之前一定要加锁。

> 08-Go并发编程实战课 07


### Once

Once 常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。

问题：Once不保证初始化行为是否真正完成。

```go

// 一个功能更加强大的Once
type Once struct {
    m    sync.Mutex
    done uint32
}
// 传入的函数f有返回值error，如果初始化失败，需要返回失败的error
// Do方法会把这个error返回给调用者
func (o *Once) Do(f func() error) error {
    if atomic.LoadUint32(&o.done) == 1 { //fast path
        return nil
    }
    return o.slowDo(f)
}
// 如果还没有初始化
func (o *Once) slowDo(f func() error) error {
    o.m.Lock()
    defer o.m.Unlock()
    var err error
    if o.done == 0 { // 双检查，还没有初始化
        err = f()
        if err == nil { // 初始化成功才将标记置为已初始化
            atomic.StoreUint32(&o.done, 1)
        }
    }
    return err
}
```


> 08-Go并发编程实战课 08


### Map

Map 不是线程安全的，有几个方法：

1. 加读写锁。

2. 分片加锁。使用多个 map 减少锁冲突概率。

3. sync.Map。有两个场景比 map+RWMutex 的方式性能要好得多：1、只会增长的缓存系统中，一个 key 只写入一次而被读很多次；2、多个 goroutine 为不相交的键集读、写和重写键值对。—— 自己做性能评测。

sync.Map 实现：

- 空间换时间。通过冗余的两个数据结构（只读的 read 字段、可写的 dirty），来减少加锁对性能的影响。对只读字段（read）的操作不需要加锁。

- 优先从 read 字段读取、更新、删除，因为对 read 字段的读取不需要锁。

- 动态调整。miss 次数多了之后，将 dirty 数据提升为 read，避免总是从 dirty 中加锁读取。

- double-checking。加锁之后先还要再检查 read 字段，确定真的不存在才操作 dirty 字段。

- 延迟删除。删除一个键值只是打标记，只有在提升 dirty 字段为 read 字段的时候才清理删除的数据。


> 08-Go并发编程实战课 09


### Pool 对象池

坑：内存泄漏。回收 buffer 的时候，一定要检查回收的对象的大小，如果 buffer 太大，就不要回收了，否则就太浪费了。

坑：内存浪费。对于 Buffer，针对不同的用量尺寸单独使用池子。

第三方库：

- bytebufferpool，底层也是使用 sync.Pool 实现的，会检测最大的 buffer，超过最大尺寸的 buffer，就会被丢弃。

- oxtoacart/bpool，最大的特色就是能够保持池子中元素的数量，一旦 Put 的数量多于它的阈值，就会自动丢弃，而 sync.Pool 是一个没有限制的池子，只要 Put 就会收进去。

Worker Pool 工作池：

- gammazero/workerpool

- vpusic/grpool

- dpaks/goworkers

大量的 goroutine 对于调度和垃圾回收的耗时还是会有影响的。

TODO 看看 08-Go并发编程实战课 10。

> 08-Go并发编程实战课 10


### Context

Context的作用：

1. 上下文信息传递。

2. 控制子Goroutine运行。

3. 超时控制的方法调用。

4. 可以取消的方法 调用。

TODO：多看看 08-Go并发编程实战课 11。

> 08-Go并发编程实战课 11


### Atomic

CPU 提供了基础的原子操作，不同架构的系统的原子操作是不一样的。因为不同的 CPU 架构甚至不同的版本提供的原子操作的指令是不同的（有的CPU架构会拆分为2个指令，比如 i386），所以，要用一种编程语言实现支持不同架构的原子操作是相当有难度的。

在现在的系统中，write 的地址基本上都是对齐的（aligned）。 比如，32 位的操作系统、CPU 以及编译器，write 的地址总是 4 的倍数，64 位的系统总是 8 的倍数。对齐地址的写，不会导致其他人看到只写了一半的数据，因为它通过一个指令就可以实现对地址的操作。如果地址不是对齐的话，那么，处理器就需要分成两个指令去处理，如果执行了一个指令，其它人就会看到更新了一半的错误的数据，这被称做撕裂写（torn write） 。

> 08-Go并发编程实战课 12


### Channel

看过源码：对象在会执行复制。

我记得，chan 类型可以降级，从双向降级为单向，这种限制有利于代码的设计。

---

使用场景：

- 数据交流。生产者-消费者问题。

- 数据传递。一个 Goroutine 将数据交给另一个 Goroutine。

- 信号通知。一个 Goroutine 将信号传递给另一个/组 Goroutine。

- 任务编排。将一组 Goroutine 按照并发和串行的方式执行。

- 锁。实现互斥锁。

---

实现原理：

阅读：go1.19.5/src/runtime/chan.go#chansend

send：

1. 第一部分是进行判断：如果 chan 是 nil 的话，就把调用者 goroutine park（阻塞休眠）， 调用者就永远被阻塞住了。

2. 当你往一个已经满了的 chan 实例发送数据时，并且想不阻塞当前调用，那么这里的逻辑是直接返回。

3. 如果 chan 已经被 close 了，再往里面发送数据的话会 panic。

4. 如果等待队列中有等待的 receiver，那么这段代码就把它从队列中弹出，然后直接把数据交给它（通过 memmove(dst, src, t.size)），而不需要放入到 buf 中，速度可以更快一些。

5. 当前没有 receiver，需要把数据放入到 buf 中，放入之后，就成功返回了。

6. 处理 buf 满的情况。如果 buf 满了，发送者的 goroutine 就会加入到发送者的等待队列中，直到被唤醒。


阅读：go1.19.5/src/runtime/chan.go#chanrecv

recv：

1. 和 send 一样，从 nil chan 中接收（读取、获取）数据时，调用者会被永远阻塞。

2. 如果 chan 已经被 close 了，并且队列中没有缓存的元素，那么返回 true、false。

3. 如果 buf 中有数据，优先从 buf 中读取数据，否则直接从等待队列中弹出一个 sender，把它的数据复制给这个 receiver。

4. 如果 buf 有元素，就取出一个元素给 receiver。

5. 如果没有元素，那么当前的 receiver 就会被阻塞，直到它从 sender 中接收了数据，或者是 chan 被 close，才返回。


close：如果 chan 为 nil，close 会 panic；如果 chan 已经 closed，再次 close 也会 panic。否则的话，如果 chan 不为 nil，chan 也没有 closed，就把等待队列中的 sender（writer）和 receiver（reader）从队列中全部移除并唤醒。

---

Channel 导致的 goroutine 泄漏：一个 Chan 在 goroutine 里发送数据，但接受端已经返回了，这个时候就会导致阻塞，从而 goroutine 泄漏。

---

Go 的开发者极力推荐使用 Channel，不过，这两年，大家意识到，Channel 并不是处理并发问题的“银弹”，有时候使用并发原语更简单，而且不容易出错。所以，我给你提供一套选择的方法:

- 共享资源的并发访问使用传统并发原语；

- 复杂的任务编排和消息传递使用 Channel；

- 消息通知机制使用 Channel，除非只想 signal 一个 goroutine，才使用 Cond；

- 简单等待所有任务的完成用 WaitGroup，也有 Channel 的推崇者用 Channel，都可以；

- 需要和 Select 语句结合，使用 Channel；

- 需要和超时配合时，使用 Channel 和 Context。

> 08-Go并发编程实战课 13

---

任务编排：

- Or-Done 模式：这是有一个任务的情况，如果有多个任务，只要有任意一个任务执行完，我们就想获得这个信号

- 扇入模式：有多个输入，一个输出。

- 扇出模式：只有一个输入源 Channel，有多个目标 Channel。

- Stream：当作流式管道使用的方式，也就是把 Channel 看作流（Stream），提供跳过几个元素，或者是只取其中的几个元素。

- Map-Reduce：第一步是映射（map），处理队列中的数据，第二步是规约（reduce），把列表中的每一个元素按照一定的处理方式处理成结果，放入到结果队列中。就像做汉堡一样，map 就是单独处理每一种食材，reduce 就是从每一份食材中取一部分，做成一个汉堡。

> 08-Go并发编程实战课 14


### 内存模型

它描述的是并发环境中多 goroutine 读相同变量的时候，变量的可见性条件。

由于指令重排，代码并不一定会按照你写的顺序执行。

happens-before：在一个 goroutine 内部，程序的执行顺序和它们的代码指定的顺序是一样的，即使编译器或者 CPU 重排了读写顺序，从行为上来看，也和代码指定的顺序一样。

应用程序的初始化是在单一的 goroutine 执行的。如果包 p 导入了包 q，那么，q 的 init 函数的执行一定 happens before  p 的任何初始化代码。

main 函数一定在导入的包的 init 函数之后执行。

【 我的理解，就是第一运行是一个goroutine，然后运行下一条语句，运行时因为重排的问题，不保证 goroutine 的执行顺序一定先于下一条语句。 】

> 08-Go并发编程实战课 15


### Semaphore信号量

Go 运行时内部使用，但并没有封装暴露成一个对外的信号量并发原语，原则上我们没有办法使用。

Go 在它的扩展包中提供了信号量：Weighted。

使用信号量遵循的原则就是请求多少资源，就释放多少资源。

> 08-Go并发编程实战课 16

### SingleFlight 请求合并 和 CyclicBarrier 循环栅栏

SingleFlight 的作用是将并发请求合并成一个请求，以减少对下层服务的压力。可以应对缓存穿透。

原理：每个函数提供一个 Key，相同Key不允许并发调用。

CyclicBarrier 是一个可重用的栅栏并发原语，用来控制一组请求同时执行的数据结构。

原理：循环栅栏的参与者只需调用 Await 等待，等所有的参与者都到达后，再执行下一步。当执行下一步的时候，循环栅栏的状态又恢复到初始的状态了，可以迎接下一轮同样多的参与者。

具体自己看 08-Go并发编程实战课 17。

> 08-Go并发编程实战课 17


### 分组操作

分组执行一批相同的或类似的任务则是任务编排中一类情形。

- ErrGroup

- bilibili/errgroup：在 ErrGroup 的基础上，增加 Pool，防止过度调用导致 GC 压力。

- neilotoole/errgroup：在 ErrGroup 的基础上，增加了可以控制并发 goroutine 的功能。

- facebookgo/errgroup：其实并不是对 Go 扩展库 ErrGroup 的扩展，而是对标准库 WaitGroup 的扩展。

- 其他。。。。

> 具体参见：08-Go并发编程实战课 18


### 分布式环境

Leader 选举：在同一时刻，系统中不能有两个主节点，否则，如果两个节点都是主，都执行写操作的话，就有可能出现数据不一致的情况，所以，我们需要一个选主机制，选择一个节点作为主节点。

互斥锁：使用互斥锁的不同节点是没有主从这样的角色的，所有的节点都是一样的，只不过在同一时刻，只允许其中的一个节点持有锁。

读写锁：etcd 提供的读写锁，可以在分布式环境中的不同的节点使用。

分布式队列：具体参见08-Go并发编程实战课20。

优先级队列：具体参见08-Go并发编程实战课20。

分布式栅栏：etcd 也提供了相应的分布式并发原语。

Barrier：分布式栅栏。如果持有 Barrier 的节点释放了它，所有等待这个 Barrier 的节点就不会被阻塞，而是会继续执行。

DoubleBarrier：计数型栅栏。在初始化计数型栅栏的时候，我们就必须提供参与节点的数量，当这些数量的节点都 Enter 或者 Leave 的时候，这个栅栏就会放开。所以，我们把它称为计数型栅栏。

STM（Software Transactional Memory，软件事务内存）：etcd 在这些基础 API 上进行了封装，提供了更加便利的方法。

> 08-Go并发编程实战课 19/20
