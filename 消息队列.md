# 消息队列

对于消息队列，主要阅读《极客时间：消息队列高手课》，技术领域围绕几个问题：

1. 消息队列的作用 和 使用场景

2. 消息队列产品的选型

3. 消息队列的基本模型

4. 消息队列怎么处理分布式事务的

5. 遇到的问题：重复消息、丢消息、消息积压

6. 热门的产品：RocketMQ、Kafka、Plusar

7. Kafka + Flink 流计算 保证 准确一次

## 上下文

- 关注的产品：JMQ 京东的秒杀消息队列：https://www.infoq.cn/article/contrast-with-kafka-and-jingdong-jmq
- 目前缺少实战演练，理论是充足的，后续还需要继续多看《极客时间：消息队列高手课》，但目的已经不是理论问题了。
- 阅读：The Log: What every software engineer should know about real-time data’s unifying abstraction（《日志：每个软件工程师都应该知道的有关实时数据的统一抽象》）。

## 应用场景

消息队列解决的问题：系统间异步处理、流量控制（削峰填谷）、服务接偶。

对于秒杀系统，本质上关键点就是 风控 + 库存锁定 两个步骤，剩下的可以交给消息队列处理。

对于流量控制，一个方法就是使用消息队列去削峰填谷，但代价就是同步改异步，复杂度提升，还有个方法就是令牌桶，生成令牌，放到消息队列，网关去消费。

对于服务解耦，通过发送信息，订阅发布，上游变化，下游都不会变化。

从架构设计的角度，带来延迟、怎么系统复杂度、可能产生数据不一致，所以适合的架构才是好架构。


## 产品选型

1. 选型除了功能满足要求外，要注意生态绑定，比如 Kafka生态就很好，Kafka + Flink，这是绑定的。
2. 产品本身的特性。

RabbitMQ 缺点：消息堆积支持不好（堆积太多，性能下降很大）、性能比较差（每秒几万到几十万）、Erlang难学。

RocketMQ 响应延迟最好，Java，每秒处理几十万，缺点就是周边生态。

Kafka 生态很好，性能最好（几十万条），因为采用等待批量发送，所以延迟比较高。

Pulsar 存储和计算分离，缺点就是存储的高可用一方面，另方面存储的网络IO延迟。


## 消息模型

刚开始是队列模型，缺点就是消费者只能有一个，而且多个队列还需要复制数据。后来是 发布-订阅模型。

RabbitMQ 消息模型：Exchange中转 来决定生成的消息投放到哪个队列。

RocketMQ 消息模型：使用队列，使用 确认机制，无论是生产还是消费，都需要发送确认才能认为是成功的，在队列里，保证顺序，并且维护一个Offset偏移，如果某个失败，丢消息，需要重新回到原来的位置。

Kafka 与 RocketMQ 同，名称不一样。

因为业务模型和实现层面的模型不同，虽然 Kafka 与 RocketMQ 相同，但具体实现是不一样的。


## 分布式事务

消息队列的事务主要解决生产者和消费者的数据一致性问题，比如创建订单，通过 MQ 通知购物车系统，然后确认购买流程。

分布式事务常见技术：2PC（两阶段提交）、TCC（尝试-确认-取消）、事务消息（适用的场景主要是那些需要异步更新数据，并且对数据实时性要求不太高的场景。）。

Kafka 在事务出错的时候，直接抛出异常，也不重试，用户自行处理。而 RocketMQ 增加事务反查机制，如果出错就回滚。


## 丢消息

首先先检测，查到丢消息了，然后再想办法补救。一般方法：

1. IT 基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。
2. 使用 拦截器 把序号注入到消息里，那只要保证每次消息序号 +1 即可，好处就是非侵入，随时删除，然后注意就是只能在分区/队列保证，最好消费者和分区一一对应。

怎么保证不丢消息：

1. 生产阶段保证：发送消息的时候要正确处理异常，才能保证消息不回丢失。
2. 存储阶段保证：1、同步刷盘。2、多节点下，至少2个节点才发送确认。
3. 消费阶段保证：执行完业务逻辑后，才确认消费。


## 重复消息

协议这一块是有服务级别的：至多一次、至少一次、恰好一次，级别越严格，拿性能去换。

一般通过幂等的方法去保证：

1. 利用数据库唯一约束，某个ID + 用户名 组合一个唯一，只要支持 INSERT IF NOT EXIST 数据库都可以，Redis也行。
2. 更新数据的时候，设定前置条件，或者使用 version 标识版本。
3. 通过分布式事务锁生成GUID，然后检查这个ID是否被消费过。

【 我觉得幂等设计在于，使用 row 而非 statement。】

## 消息积压

在 重计算轻存储 的消息队列中，基本上问题在 发送端 和 消费端，中间 Broker 几乎没有压力。

发送端：主要就是保证业务逻辑的执行速度，基本上没影响。

消费端：确保设计的时候，消费端能力比发送端强。然后优化消费业务逻辑，可以水平扩容，增加分区和消费者数量（保证一一对应）。

经验手段：
1. 先确定生产多了，还是消费多了，比如活动什么的，消息队列都有监控，可以确定。
2. 如果短期内活动，可以考虑消费端扩容 或者 服务降级。
3. 还有一种特殊情况：有没有反复消费同一个消息，因为如果事务出问题了，直接回滚。

如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。


## Kafka 和 RockeMQ

### Kafka 高性能的秘密
1. 批量信息，合并和减少不必要的元数据。
2. 顺序读写磁盘提升IO性能。
3. PageCache 磁盘文件内存缓存，利用一个信息写入马上就会消费的特点，直接从内存中读取文件。
4. 零拷贝：一般都是从 PageCache 拷贝到内存空间，然后从内存空间拷贝到Socket缓冲区，现在直接从 PageCache 到 Socket缓冲区，就不需要CPU参与，直接DMA控制器负责传输。
5. Kafka 在对数据压缩（用时间换空间），以批为单位，这样Broker就直接发送给消费者，不需要中转解压。
6. 有个东西，用 CAS 代替 Mutex，因为 Mutex = CAS + 信号量。

### 基本原理

因为读写缓存在停电的情况下导致丢失，所以 Kafka 使用多节点才保证高可用。

一般通过多个节点复制消息保证可用和可靠，然而，写入的节点数量越多，性能越低，是一个矛盾。对于一致性来说，主从架构严格保证的。为了保证高可用，还需要具备选举切换主节点的。

RocketMQ 对于信息复制 提供两个方法，一个是异步，一个是同步双写，前者不会丢消息，因为不支持动态切换，哪怕主挂了，数据还在主的磁盘里，只要恢复主节点就好，所以那可用性换性能和数据一致性。而为了解决可用性，将数据通过分片的形式分配到多个 主-从 架构里，但问题也就是，主题顺序无法得到保证。而引入了 Dledger，拿性能换可用性，写入一定数量节点才返回成功，当主节点挂掉，动态选举切换。

Kafka 复制单位是分区，每个分区的副本之间构成复制集群，分区副本之间是 主从架构，写入一定节点才返回成功，然后使用 ZooKeeper 来选举新的主节点。

Kafka 使用 Zookeeper 保证高可用和选举动态切换，很依赖 Zookeeper，所以在使用的时候考虑 Zookeeper 的高可用，目前团队在考虑自己开发一个元数据服务。https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum 

### 事务

RocketMQ 如何实现事务？通过二阶段提交的方式，发送半消息后，执行本地事务，检查反查机制，确定是提交还是回滚，主要保证本地事务和消息队列是否同时完成。【半消息我的理解就是提交到broker里，因为只要提交到broker里，就是最终一致性的。】

Kafka 确保一个事务中多条消息，要么都成功，要么都失败，并且没有反查机制。在实现这一块，通过协调者记录事务日志，一旦收到事务结束信息，就放行给消费者。


## MQTT 支持海量在线IoT设备

IoT设备的特点：支持数量极为庞大（日在线十万对京东来说足够全部人民买买买了，而IoT设备可能几百万在线），协议不能复杂，功能不能太多，而且经常网络不稳定。所以 MQTT 精简协议，惜字如金，仅仅收发信息和订阅发布功能，另外加入心跳机制。由于 MQTT 不支持点与点通信，所以每个客户端拥有自己的ID，订阅相关的主题，所以主题数量跟客户端数量同规模。

在技术选型上，如果规模十万以内，可以使用开源产品，注意RocketMQ和Kafka的 NameServer 都不能支持大量数据。而开源的MQTT没有集群，所以只能买企业版的服务了。

支持海量主题的思路，前置通过负载均衡、，使用多组Kafka小集群，通过分片算法分担压力。

## Pulsar

Pulsar 的Broker是无状态的，不保存任何数据。
缺点就是计算和存储分离，中间会有n次通信和内存拷贝，性能会低一点，当然复杂度降低了，使用外部成熟的存储系统即可。

关于存储计算分离，早期消息队列仅仅是一个管道的作用，后来加入了持久化到磁盘，更大的信息堆积能力。而存储计算分离，降低了性能一方面，另方面没有通用的存储系统使用，而且绝大多数功能都在存储系统里，计算节点没有太多业务逻辑。而 Pulsar 采用是因为 大趋势 —— 流计算，因为现有的流计算产品都是只计算不存储，而消息队列是只存储不计算，所以未来需要一个 Pulsar 这样的两者兼备的消息队列。

## Kafka + Flink

Kafka 和 Flink 如何实现端到端 Exactly Once，Kafka 开启一个事务，对应 Flink 一个 CheckPoint 点，要么成功，要么回滚重来。


