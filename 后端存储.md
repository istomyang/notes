# 后端存储

## 摘录

存储是系统中最核心、最重要、最关键的组成部分，没有之一。

存储的特点：难用、慢、杂。

一个经过良好优化过的业务系统，它的性能瓶颈一定是存储。从性能角度上来说，存储系统就是整个系统中最短的那块儿板子，存储系统有多慢，你的整个系统就多慢。如何优化存储性能，从而让整个系统运转如飞，这里面同样有很多的方法、技巧和经验需要掌握。

MySQL、Redis、ElasticSearch、HBase、Hive、MongoDB、RocksDB、CockroachDB 等等，这些存储还真就是谁都替代不了谁，每一种都有它擅长的地方，有它适用的场景，当然也有很突出的短板。

很多培训学校、各种技术论坛都特别喜欢讲电商系统。因为电商这个系统，特别有代表性，特别适合作为案例来研究和学习。

电商系统覆盖面足够广泛，特别是是在互联网行业，你会发现几乎所有的互联网公司都在做两个事情：电商和社交。

用电商系统作为案例，直接就能学以致用。即使你面对的业务和电商关系不大，因为电商的系统足够复杂，你在其他业务中可能遇到的技术问题，大多数在电商系统中基本都会遇到，一样有借鉴的意义。另外，电商这个业务领域对所有人来说都很熟悉，拿它作为案例基本上不需要再讲解业务知识，我们可以快速地专注于技术问题本身。

即使是同样一个电商系统，不同的规模，它需要解决的问题也不一样。不少做技术的同学崇尚于海量数据和高并发，认为只有大厂那些高并发、海量数据的核心或者是底层存储系统，才是真正“有技术含量”的系统，能胜任这样系统的开发者，才是真正的技术大牛。

创业团队需要快速低成本把系统完整地实现出来，好快速验证它的商业模式；处于高速增长期的团队，它面临的问题是业务高速增长和不断变化，相应的，也要对系统不停地进行升级改造来适应变化，并且要在变化的过程中确保稳定；业务规模足够大的一些大厂，它需要解决的是如何应对高并发、海量数据这些问题。

不同规模的系统，在技术上没有高低贵贱之分，它们的建设目标不一样，面临的挑战不一样，需要解决的问题也不一样，对于存储系统的选择、架构设计也是不一样的。

> 117-后端存储实战课-0

在需求还不太明确的情况下，比较可行的方式就是，先把那些不太会变化的核心系统搭建出来，尽量简单地实现出一个最小化的系统，然后再逐步迭代完善。

可以根据流程来划分功能模块。

> 117-后端存储实战课-课前加餐| 电商系统是如何设计的？


## 保证数据无误

订单保证数据无误：代码逻辑对 + 会使用事务。

---

利用 基础的订单系统 体会一下建表

基础功能：

- 创建订单；

- 随着购物流程更新订单状态；

- 查询订单，包括用订单数据生成各种报表。

至少表：

- 订单主表：也叫订单表，保存订单的基本信息。

- 订单商品表：保存订单中的商品信息。

- 订单支付表：保存订单的支付和退款信息。

- 订单优惠表：保存订单使用的所有优惠信息。

---

避免重复下单

原因：

1. 前端页面上应该防止用户重复提交表单。

2. 网络错误会导致重传，很多 RPC 框架、网关都会有自动重试机制。

解决：让你的订单服务具备幂等性。

可以利用数据库的这种“主键唯一约束”特性，在插入数据的时候带上主键，来解决创建订单服务的幂等性问题。

给订单系统增加一个“生成订单号”的服务，这个服务没有参数，返回值就是一个新的、全局唯一的订单号。在用户进入创建订单的页面时，前端页面先调用这个生成订单号服务得到一个订单号，在用户提交订单的时候，在创建订单的请求中带着这个订单号，而这个订单号也是我们订单表的主键。

【 Change buffer 会失效，但是订单提交可以忍受这样的延迟。 】

---

ABA问题：一个数据，修改了两次，第一次响应丢失了，第二次修改数据的时候，由于第一次客户端会重试，这个时候又发了一遍，结果是第一次的数据。

解决：版本号，每次查询订单的时候，版本号需要随着订单数据返回给页面。页面在更新数据的请求中，需要把这个版本号作为更新请求的参数，再带回给订单更新服务。

```sql
UPDATE orders set tracking_number = 666, version = version + 1
WHERE version = 8;
```

> 117-后端存储实战课-1


## 大流量数据系统设计

DAU：日均访问次数

SKU：库存单元，在电商行业，你可以直接理解为“商品”。

典型的场景：商品详细页：高并发 + 几亿数量 + 单个重量大（各种信息/图片/视频/AR）

解决方案：分开存储（不同类型使用不同数据库），然后 分而治之。

- 对于基本信息这些静态的数据，数据库单独建表，并且配合 Redis、Memchched 等旁路缓存。

- 考虑是否需要保存历史版本的商品数据，因为某些订单系统，需要做商品的快照，防止后期更新。

- 对于不固定的非结构化信息，可以考虑使用 MongoDB，其实可以使用 MongoDB 代替 MySQL。

- 对于视频/音频/图片，数据表仅记录对应ID，本体则存放到 对象存储 里，比如 七牛云，OSS。客户端获取的时候，直接从 对象存储 拿，不需要从后端拿，而且基本上自带 CDN 服务，有些厂商还提供图片和视频转码，自定义尺寸。

- 对于静态的信息，可以生成静态 HTML，使用 CDN 提供加速。


> 117-后端存储实战课-2


### 用户存储/暂时存储

用户未登录的时候产生的数据，就是 暂时存储，这种情况是保存到客户端本地比较好。

用户存储就需要把数据保存到服务端，这个其实就简单了，用 MySQL 保存，或者 MongoDB。


> 117-后端存储实战课-3


## 事务

存储余额一个表，然后流水账一个表，并且只能添加不能删除，可以取消，这样但余额不一致的时候，可以根据流水账重新校正。

还有一种利用 MySQL 事务性。

---

2PC，二阶段提交，二阶段指的是准备阶段和提交阶段，准备阶段 就是把事情全部做好，这个阶段失败可以回滚事务，如何进入提交阶段，只要成功，不能失败，如果网络不好，需要反复重试提交，直到成功。

2PC 是一种强一致的设计，它可以保证原子性和隔离性。

2PC 也有很明显的缺陷，整个事务的执行过程需要阻塞服务端的线程和数据库的会话，所以，2PC 在并发场景下的性能不会很高。只有在需要强一致、并且并发量不大的场景下，才考虑使用 2PC。

2PC 协调者是一个单点，一旦过程中协调者宕机，就会导致订单库或者促销库的事务会话一直卡在等待提交阶段，直到事务超时自动回滚。卡住的这段时间内，数据库有可能会锁住一些数据，服务中会卡住一个数据库连接和线程，这些都会造成系统性能严重下降，甚至整个服务被卡住。


3PC：三阶段提交，2PC的改良版本，协调者和参与者均引入超时机制，通过超时机制来解决2PC的同步阻塞问题，避免事务资源被永久锁定。

3PC是指三阶段提交（3PC），是二阶段提交（2PC）的一个改良版本，引入了两个新的特性：

1. 协调者和参与者均引入超时机制，通过超时机制来解决2PC的同步阻塞问题，避免事务资源被永久锁定。

2. 把二阶段演变为三阶段，二阶段提交协议中的第一阶段"准备阶段"一分为二，形成了"CanCommit"和"PreCommit"两个阶段。

TCC：Try-Confirm-Cancel，每个分支事务实现三个操作：预处理 Try、确认 Confirm、撤销 Cancel。Try 操作做业务检查及资源预留，Confirm 做业务确认操作，Cancel 实现一个与 Try 相反的操作既回滚操作。

---

本地消息表：分布式最终一致性

思路：

1. 订单服务在收到下单请求后，正常使用订单库的事务去更新订单的数据，并且，在执行这个数据库事务过程中，在本地记录一条消息，比如 “清空购物车”。这样保证 订单库 和 本地信息 的一致性。

2. 用一个异步的服务，根据本地信息去清空购物车，重试直到成功，然后标记为已完成。

3. 最终，可以保证订单系统和购物车系统它们的数据是一致的。

消息队列提供的事务消息就是 本地消息表 的一个实现，可以使用消息队列实现最终一致性。 

本地信息表 的异步部分，不能锁定库存和执行时效性的任务。


> 117-后端存储实战课-4
> 117-后端存储实战课-5


### ES 商品搜索

> 117-后端存储实战课-6


## MySQL HA

MySQL 备份是 定期的全量备份，配合 Binlog，具体参阅 MySQL官方文档的备份和恢复。

注意：无论是全量备份还是 Binlog，都不要和数据库存放在同一个服务器上。最好能做到不同机房，甚至不同城市，离得越远越好。这样即使出现机房着火、光缆被挖断甚至地震也不怕。

注意：在回放 Binlog 的时候，指定的起始时间可以比全量备份的时间稍微提前一点儿，确保全量备份之后的所有操作都在恢复的 Binlog 范围内，这样可以保证恢复的数据的完整性。前提是 ROW 格式。

至于 HA，主备，参阅专业 MySQL 笔记。


> 117-后端存储实战课-7


## 数据库超时

在每一次数据库访问的时候，先考虑清楚它的性能，能否撑得住高并发，然后再思考能否将结果做缓存。

考虑缓存的问题：命中率、穿透、击穿、雪崩 的问题。

那些大厂，几万开发人员，每天会上线无数的 Bug，而大厂的系统都是比较稳定的，基本上不会出现全站无法访问这种情况。靠的是架构。优秀的系统架构，可以在一定程度上，减轻故障对系统的影响。

建议：

1. 上线一个定时监控和杀掉慢 SQL 的脚本。这个脚本每分钟执行一次，检测上一分钟内，有没有执行时间超过一分钟（这个阈值可以根据实际情况调整）的慢 SQL，如果发现，直接杀掉这个会话。

2. 做一个简单的静态页面的首页作为降级方案，只要包含商品搜索栏、大的品类和其他顶级功能模块入口的链接就可以了。

其他 MySQL 问题参考专业 MySQL 笔记。

> 117-后端存储实战课-8/9/10/11/12/13/14/15


## 缓存系统：Redis

Redis集群采用分布式的注册中心，导致不能构件超大规模集群，但可以使用前置代理，使用多个集群。

> 117-后端存储实战课-16

## MySQL to Redis同步

使用消息队列去更新。

使用 Binlog 实时更新 Redis 缓存，使用 Canal 解析 Binlog。


> 117-后端存储实战课-17


## 分布式存储

大的对象被拆分为若干固定大小的块儿，块儿又被封装到容器（也就分片）中，每个容器有一主 N 从多个副本，这些副本再被分散到集群的数据节点上保存。

所有分布式存储系统共通的一些特性：数据如何分片，如何通过多副本保证数据可靠性，如何在多个副本间复制数据，确保数据一致性等等。

> 117-后端存储实战课-18


##  跨系统实时同步数据

使用 Binlog 和 MQ 构建实时数据同步系统

保证数据同步的实时性：一般容易成为性能瓶颈的就是消费 MQ 的同步程序。

为了确保数据一致性，Binlog 的顺序很重要，是绝对不能乱序的。

> 117-后端存储实战课-19


## 不停机更换数据库

1. 上线同步程序，从旧库中复制数据到新库中，并实时保持同步；

2. 上线双写订单服务，只读写旧库；

3. 开启双写，同时停止同步程序；

4. 开启对比和补偿程序，确保新旧数据库数据完全一样；

5. 逐步切量读请求到新库上；

6. 下线对比补偿程序，关闭双写，读写都切换到新库上；

7. 下线旧库和订单服务的双写功能。

> 117-后端存储实战课-20


## 海量数据存储

---

使用 Kafka 来存储，现代的消息队列，本质上就是分布式的流数据存储系统。

Kafka 官方给自己的定位也是“分布式流数据平台”，不只是一个 MQ。

Kafka 提供“无限”的消息堆积能力，具有超高的吞吐量，可以满足我们保存原始数据的大部分要求。

Kafka 存储分片落在某个节点上，其存储瓶颈在于单个节点的存储容量。

---

使用 HDFS 来存储。

对于保存海量的原始数据这个特定的场景来说，HDFS 的吞吐量是远不如 Kafka 的。

Kafka 的吞吐能力很容易达到每秒钟大几百兆，而 HDFS 只能达到百兆左右。这就意味着，要达到相同的吞吐能力，使用 HDFS 就要比使用 Kafka，多用几倍的服务器数量。

HDFS优势：

1. 它能提供真正无限的存储容量，如果存储空间不够了，水平扩容就可以解决。

2. HDFS 能提供比 Kafka 更强的数据查询能力。Kafka 只能按照时间或者位点来提取数据，而 HDFS 配合 Hive 直接就可以支持用 SQL 对数据进行查询，虽然说查询的性能比较差，但查询能力要比 Kafka 强大太多了。

---

目前还没有可用大规模于生产的，成熟的解决方案，但未来应该会有的：

- 分布式流数据存储，比较活跃的项目有Pravega和 Pulsar 的存储引擎Apache BookKeeper。京东的流数据存储项目JournalKeeper。

- 时序数据库（Time Series Databases），比较活跃的项目有InfluxDB和OpenTSDB等。不仅有非常好的读写性能，还提供很方便的查询和聚合数据的能力。但是只能存储类似监控数据这样的，有时间特征的。

> 117-后端存储实战课-21


### 海量数据查询

一般的做法是，用流计算或者是批计算，把原始数据再进行一次或者多次的过滤、汇聚和计算，把计算结果落到另外一个存储系统中去，由这个存储再给业务系统提供查询支持。这里的“流计算”，指的是 Flink、Storm 这类的实时计算，批计算是 Map-Reduce 或者 Spark 这类的非实时计算。

有的业务，计算后的数据非常少，比如说一些按天粒度的汇总数据，或者排行榜类的数据，用什么存储都能满足要求。

有一些业务，没法通过事先计算的方式解决全部的问题。原始数据经过计算后产生的计算结果，数据量相比原始数据会减少一些，但仍然是海量数据。

---

ETL：数据抽取

存储级别：

1. GB量级：MySQL 仍然是可以考虑的，因为它的查询能力足以应付大部分分析系统的业务需求。

2. 10GB量级：可以选择一些列式数据库，比如：HBase、Cassandra、ClickHouse，能做到秒回，代价就是查询不够灵活。还有值得考虑的选择是 Elasticsearch（ES），ES 的查询能力和灵活性是要强于上述这些列式数据库的，缺点就是需要大内存服务器，成本高。

2. TB级：这个时候的性能瓶颈已经是磁盘 IO 和网络带宽了，实时的查询和分析肯定做不了。解决的办法都是，定期把数据聚合和计算好，然后把结果保存起来，在需要时对结果再进行二次查询。这么大量级的数据，一般都选择保存在 HDFS 中，配合 Map-Reduce、Spark、Hive 等等这些大数据生态圈产品做数据聚合和计算。

存储系统没有银弹，不要指望简单地更换一种数据库，就可以解决数据量大，查询慢的问题。

最近很火的 RocksDB、LevelDB，它们的存储结构 LSM-Tree，其实就是日志和跳表的组合，单从数据结构的时间复杂度上来说，和“老家伙”MySQL 采用的 B+ 树，有本质的提升吗？没有吧，时间复杂度都是 O(log n)。但是，LSM-Tree 在某些情况下，它利用日志有更好的写性能表现。


> 117-后端存储实战课-22


## New SQL

- 完整地支持 SQL 和 ACID，提供和 Old SQL 隔离级别相当的事务能力；

- 高性能、高可靠、高可用，支持水平扩容。

像 Google 的 Cloud Spanner、国产的 OceanBase 以及开源的CockroachDB都属于 New SQL 数据库。Cockroach 这个英文单词是蟑螂的意思，所以一般我们都把 CockroachDB 俗称为小强数据库。

CockroachDB 的存储引擎是一个分布式的 KV 存储集群。

> 117-后端存储实战课-23


## RocksDB

RocksDB是 Facebook 开源的一个高性能持久化 KV 存储。

RocksDB 采用了一个非常复杂的数据存储结构，并且这个存储结构采用了内存和磁盘混合存储方式，使用磁盘来保证数据的可靠存储，并且利用速度更快的内存来提升读写性能。或者说，RocksDB 的存储结构本身就自带了内存缓存。

LSM-Tree 通过混合内存和磁盘内的多种数据结构，将随机写转换为顺序写来提升写性能，通过异步向下合并分层 SSTable 文件的方式，让热数据的查找更高效，从而获得还不错的综合查找性能。

 LSM-Tree 这种数据结构还是偏向于写入性能的优化，更适合在线交易类场景，因为在这类场景下，需要频繁写入数据。

> 117-后端存储实战课-24














